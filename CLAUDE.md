# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Code Quality Standards

**CRITICAL IMPLEMENTATION RULES:**
- **NEVER create workarounds** - Always fix root causes, not symptoms
- **NEVER use fallback patterns** - Implement proper solutions that handle edge cases correctly
- **NEVER write overengineered code** - Keep implementations simple, direct, and maintainable
- **NEVER add redundant or verbose code** - Every line must serve a clear purpose
- **ALWAYS use best practices** for MATLAB and this project's architecture
- **ALWAYS consider side effects** of changes across the entire pipeline
- **ALWAYS implement bulletproof solutions** that handle edge cases without defensive bloat
- **ALWAYS analyze root causes** before proposing solutions
- **ASK QUESTIONS if stuck** - Do not add fallback algorithms instead; clarify requirements first

**Naming and Documentation Standards:**
- Variable names: descriptive nouns without opinions or history
- Function names: verb phrases describing actions
- Constants: ALL_CAPS with units if applicable
- Comments: state facts only, no opinions or historical notes
- Use git history for tracking changes, not code comments

When fixing bugs:
1. Identify the root cause, not just the symptom
2. Fix the underlying issue, not the manifestation
3. Ensure the fix doesn't introduce technical debt
4. Validate the fix handles all edge cases naturally

## Project Overview

This is a MATLAB-based colorimetric analysis pipeline for microPAD (microfluidic Paper-based Analytical Device) analysis. The pipeline processes raw microPAD images through multiple stages to extract colorimetric features for concentration prediction.

### Experimental Design

**Final microPAD design:** Each paper strip contains 7 test zones. Each test zone has 3 elliptical regions designed for 3 different chemicals:
1. **Region 1:** Urea
2. **Region 2:** Creatinine
3. **Region 3:** Lactate

**Training data collection:** To train machine learning models for each chemical separately, experiments are conducted where all 3 elliptical regions in each test zone are filled with the **same concentration** of a **single chemical**. This provides 3 replicate measurements per concentration level, resulting in separate datasets for urea, creatinine, and lactate.

## Pipeline Architecture

The codebase implements a **5-stage sequential colorimetric analysis pipeline** where each stage consumes the output of the previous stage:

### Stage Flow
```
1_dataset (raw images)
    -> crop_micropad_papers.m
2_micropad_papers (cropped paper strips)
    -> cut_concentration_rectangles.m
3_concentration_rectangles (polygonal concentration regions)
    -> cut_elliptical_regions.m
4_elliptical_regions (elliptical patches + coordinates)
    -> extract_features.m
5_extract_features (feature tables)
```

Additionally, `augment_dataset.m` creates synthetic training data from stage 2 outputs:
```

2_micropad_papers
    -> augment_dataset.m
augmented_1_dataset (synthetic scenes)
augmented_2_concentration_rectangles (transformed polygons)
augmented_3_elliptical_regions (transformed ellipses)
```
### Key Design Principles

1. **Stage Independence**: Each script reads from `N_*` and writes to `(N+1)_*`
2. **Phone-based Organization**: Data is organized by phone model subdirectories (e.g., `iphone_11/`, `samsung_a75/`)
3. **Concentration Folders**: Stages 3-4 use `con_0/`, `con_1/`, etc. subfolders
4. **Consolidated Coordinates**: Coordinate files are stored at phone-level (not per-image) to avoid duplication

## Running the Pipeline

### Individual Stages
All scripts use dynamic project root resolution (searches up to 5 directory levels):

```matlab
% Stage 1: Crop microPAD paper strips from raw images
cd matlab_scripts
crop_micropad_papers()

% Stage 2: Cut concentration regions from paper strips
cut_concentration_rectangles('numSquares', 7)  % 7 regions per strip

% Stage 3: Extract elliptical patches from concentration regions
cut_elliptical_regions()

% Stage 4: Extract features from elliptical patches
extract_features('preset', 'robust', 'chemical', 'lactate')

% Data Augmentation (run between stages 2-3 for synthetic data)
augment_dataset('numAugmentations', 5, 'rngSeed', 42)
```

### Common Parameters
- All scripts accept name-value pairs for configuration
- `preserveFormat`: Keep original image formats
- `jpegQuality`: JPEG compression quality when writing
- `saveCoordinates`: Write coordinate metadata files

## File Naming Conventions

### Coordinate Files
- **Stage 2**: `coordinates.txt` format: `image x y width height rotation`
- **Stage 3**: `coordinates.txt` format: `image concentration x1 y1 x2 y2 x3 y3 x4 y4` (4 polygon vertices)
- **Stage 4**: `coordinates.txt` format: `image concentration replicate x y semiMajorAxis semiMinorAxis rotationAngle`

### Output Files
- Stage 2 crops: `{original_name}.{ext}`
- Stage 3 crops: `{base}_con_{N}.{ext}` in `con_{N}/` folders
- Stage 4 patches: `{base}_con{N}_rep{M}.{ext}` in `con_{N}/` folders
  - Note: `rep{M}` represents replicate measurements (M = 0, 1, 2). In the final microPAD design, these correspond to three different chemicals (urea, creatinine, lactate). During training, all 3 replicates contain the same chemical at the same concentration.
- Stage 5 features: `{chemical}_features.xlsx`

### Corner Label Files (Augmentation Output)
When `augment_dataset.m` is run with `exportCornerLabels=true`, it generates training labels for AI polygon detection:
- **JSON**: `{imageName}.json` - Metadata only (corners, image info, MAT file reference)
- **MAT**: `{imageName}_heatmaps.mat` - Heatmaps and offsets (HDF5 compressed)

**Format:**
- JSON structure:
  ```json
  {
    "image_name": "synthetic_001",
    "image_size": [3000, 4000],
    "downsample_factor": 4,
    "heatmap_sigma": 3,
    "heatmap_format": "mat-v7.3",
    "heatmap_file": "synthetic_001_heatmaps.mat",
    "heatmap_dataset": "corner_heatmaps",
    "offset_dataset": "corner_offsets",
    "quads": [
      {
        "quad_id": 1,
        "corners": [[x1,y1], [x2,y2], [x3,y3], [x4,y4]],
        "corners_normalized": [[nx1,ny1], [nx2,ny2], [nx3,ny3], [nx4,ny4]],
        "embedding_id": 1
      }
    ]
  }
  ```
- MAT arrays:
  - `corner_heatmaps`: (4, H/4, W/4, N) single precision - Gaussian targets per corner type
  - `corner_offsets`: (4, 2, N) single precision - Sub-pixel offsets [0-1] per corner

**Loading (MATLAB):**
```matlab
data = load('synthetic_001_heatmaps.mat');
heatmaps = data.corner_heatmaps(:,:,:,1);  % First quad (4, H/4, W/4)
offsets = data.corner_offsets(:,:,1);      % First quad (4, 2)
```

**Loading (Python):**
```python
from scipy.io import loadmat
import json

# Load metadata
with open('synthetic_001.json', 'r') as f:
    metadata = json.load(f)

# Load heatmaps
mat_data = loadmat('synthetic_001_heatmaps.mat')
heatmaps = mat_data['corner_heatmaps'][:,:,:,0]  # First quad (4, H/4, W/4)
offsets = mat_data['corner_offsets'][:,:,0]      # First quad (4, 2)
```

**Storage Savings:** ~12GB â†’ ~2GB for 24,000 labels (6x reduction with HDF5 compression)

## Critical Implementation Details

### Coordinate File Management
**All coordinate files use atomic write pattern** (temp file + move) to prevent corruption:
```matlab
tmpPath = tempname(targetFolder);
fid = fopen(tmpPath, 'wt');
% ... write data ...
fclose(fid);
movefile(tmpPath, coordPath, 'f');
```

**No duplicate rows per image**: Scripts automatically filter existing entries before appending new coordinates.

### Image Orientation Handling
All scripts use `imread_raw()` helper function that:
- Inverts EXIF 90-degree rotations (tags 5/6/7/8) to preserve raw sensor layout
- Ignores flips/180-degree rotations (tags 2/3/4)
- Prevents double-rotation when user manually rotates images

### Geometry and Projection
- **Stage 2**: Simple rotation + rectangular crop
- **Stage 3**: 3D perspective projection model with fixed reference rectangle
  - Uses homography transformations for realistic camera viewpoints
  - Supports x/y/z slider controls for camera position
- **Stage 4**: Ellipse geometry with axis-aligned bounding box calculation
  - Rotation angle in degrees (-180 to 180), clockwise from horizontal
  - Constraint: `semiMajorAxis >= semiMinorAxis` (enforced for extract_features.m compatibility)

### Augmentation Strategy
`augment_dataset.m` generates synthetic training data for polygon detection training by:
1. Back-projecting Stage 2 strip coordinates into Stage 1 image space using recorded crop metadata
2. Applying shared perspective and rotation per paper (+/-60 deg pitch/yaw, 0-360 deg roll)
3. Optional independent rotation per region
4. Placing regions via grid-accelerated random sampling (guaranteed non-overlapping)
5. Compositing onto procedural backgrounds drawn from uniform, speckled, laminate, and skin surface pools (cached variants with jitter)
6. Adding moderate-density distractor artifacts
7. Applying color-safe photometric augmentation (brightness/contrast, white balance, saturation/gamma)
8. Optionally adding at most one blur type (motion or Gaussian) and thin occlusions

**Performance optimizations (v2):**
- Grid-based spatial acceleration for O(1) collision detection (vs O(n^2))
- Simplified polygon warping without alpha blending (3x faster)
- Background texture pooling (reuses 4 procedural types from cached pools instead of regenerating each frame)
- Artifact density: 5-40 per image (optimized from 1-100)
- Artifact rendering: Sharp by default with nearest-neighbor upscaling (matches polygon sharpness)
- Scene-wide blur: Optional 25% probability applied uniformly to entire image
- Overall speedup: 3x (1.0s vs 3.0s per augmented image)

**Key parameters:**
- `numAugmentations`: number of synthetic versions per original
- `independentRotation`: enable per-polygon rotation
- `occlusionProbability`: thin occlusions across polygons
- `exportCornerLabels`: emit JSON keypoint labels for passthrough, synthetic, and scale outputs
- `backgroundWidth/Height`: output dimensions

### Interactive GUI Sessions
All interactive scripts maintain **persistent memory** across images in the same folder:
- Stores last-used positions, rotations, or ellipse parameters
- Scales stored positions when image dimensions change
- First image establishes baseline; subsequent images use saved settings

### Batch Processing (extract_features.m)
- Adaptive batch sizing based on dataset size and available memory
- Small datasets (<10 files): process all at once
- Medium datasets (10-50): 3-batch split
- Large datasets (>50): dynamic batch size calculation
- Memory threshold: 80% to prevent out-of-memory errors

## Feature Extraction

### Presets
- **minimal**: Essential color ratios and basic statistics
- **robust**: Comprehensive feature set (recommended)
- **full**: All available features
- **custom**: User-defined feature groups via dialog or struct

### Output Format
- Excel (.xlsx) with train/test split option
- Optional Label column for downstream ML
- Feature names follow registry convention: `GroupName_FeatureName`

## Testing and Development

### Adding New Features
1. Register feature in feature registry (lines 100-300 in extract_features.m)
2. Implement extraction function with signature: `function val = extract_{feature}(patchImg, ellipseParams, ...)`
3. Add to appropriate feature group preset

### Debugging Tips
- Check `coordinates.txt` for malformed entries (causes silent failures)
- Verify polygon vertex order (clockwise from top-left)
- Confirm ellipse axes constraint: major >= minor
- Script complexity (approximate line counts):
  - augment_dataset.m: ~2730 lines (label export, crop transforms, texture pooling)
  - crop_micropad_papers.m: ~1889 lines
  - cut_concentration_rectangles.m: ~1726 lines
  - cut_elliptical_regions.m: ~1457 lines
  - extract_features.m: ~4440 lines (largest, most complex)

## Common Issues

### Path Resolution Failures
Scripts search up to 5 directory levels for project root. If warnings appear:
```
Could not find input folder "X_*". Using current directory as project root.
```
Solution: Run from `matlab_scripts/` or project root directory.

### EXIF Orientation Conflicts
If images appear rotated after cropping, check EXIF orientation tags. The pipeline intentionally preserves on-disk layout.

### Coordinate File Corruption
Atomic writes prevent most corruption, but if coordinates.txt is malformed:
1. Delete the corrupted file
2. Re-run the stage to regenerate from scratch
3. Check for trailing newlines or mixed delimiters

### Memory Errors in Feature Extraction
If `extract_features.m` runs out of memory:
```matlab
% Reduce batch size explicitly (overrides adaptive sizing)
extract_features('preset', 'robust', 'batchSize', 5)
```
