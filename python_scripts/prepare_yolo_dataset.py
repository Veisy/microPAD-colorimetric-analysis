"""
Prepare YOLO dataset configuration and train/val splits for microPAD auto-detection.

This script restructures the augmented dataset for YOLO training:
1. Generates YOLO labels from MATLAB coordinates (augmented_2_micropads/coordinates.txt)
2. Moves images from augmented_1_dataset/[phone]/ to augmented_1_dataset/[phone]/images/
3. Creates labels in augmented_1_dataset/[phone]/labels/
4. Creates train.txt and val.txt with absolute paths

MATLAB scripts (augment_dataset.m) generate images and polygon coordinates.
This Python script converts coordinates to YOLO format and restructures directories.

Configuration:
    - Train phones: iphone_11, iphone_15, realme_c55
    - Val phone: samsung_a75

Usage:
    python prepare_yolo_dataset.py
"""

import os
import shutil
from pathlib import Path
from typing import List, Tuple
import yaml
import cv2

# Configuration
PROJECT_ROOT = Path(__file__).parent.parent
AUGMENTED_DATASET = PROJECT_ROOT / "augmented_1_dataset"
PHONE_DIRS = ["iphone_11", "iphone_15", "realme_c55", "samsung_a75"]
VAL_PHONE = "samsung_a75"  # Reserve one phone for validation
TRAIN_PHONES = [p for p in PHONE_DIRS if p != VAL_PHONE]

# Output paths
CONFIGS_DIR = PROJECT_ROOT / "python_scripts" / "configs"
CONFIGS_DIR.mkdir(exist_ok=True)


def restructure_for_yolo() -> int:
    """Restructure dataset to YOLO-compatible format.

    Moves images from phone root to images/ subdirectory if not already there.
    Labels stay in labels/ subdirectory (MATLAB already puts them there).
    Function is idempotent - safe to run multiple times.

    Returns:
        Number of images moved
    """
    total_moved = 0

    for phone in PHONE_DIRS:
        phone_path = AUGMENTED_DATASET / phone
        images_dir = phone_path / "images"

        images_dir.mkdir(exist_ok=True)

        images_in_root = []
        for ext in ["*.jpg", "*.jpeg", "*.png"]:
            for img_path in phone_path.glob(ext):
                if img_path.parent == phone_path:
                    images_in_root.append(img_path)

        if not images_in_root:
            continue

        moved_count = 0
        for img_path in images_in_root:
            dest_path = images_dir / img_path.name
            if not dest_path.exists():
                shutil.move(img_path, dest_path)
                moved_count += 1

        if moved_count > 0:
            print(f"  {phone}: moved {moved_count} images to images/")
            total_moved += moved_count

    return total_moved


def collect_image_paths(phone_dir: str, use_absolute_paths: bool = True) -> List[str]:
    """Collect all image paths from a phone directory.

    Args:
        phone_dir: Phone directory name (e.g., 'iphone_11')
        use_absolute_paths: If True, return absolute paths; if False, return relative paths

    Returns:
        Sorted list of image paths (absolute by default)

    Raises:
        FileNotFoundError: If images/ directory does not exist
        ValueError: If no images found in directory
    """
    phone_path = AUGMENTED_DATASET / phone_dir / "images"

    if not phone_path.exists():
        raise FileNotFoundError(f"Images directory not found: {phone_path}")

    images = []
    for ext in ["*.jpg", "*.jpeg", "*.png"]:
        images.extend(phone_path.glob(ext))

    if not images:
        raise ValueError(f"No images found in {phone_path}")

    if use_absolute_paths:
        images = [str(img.absolute()) for img in images]
    else:
        images = [f"{phone_dir}/images/{img.name}" for img in images]

    return sorted(images)


def generate_yolo_labels() -> Tuple[int, int]:
    """Generate YOLO segmentation labels from MATLAB coordinates.

    Reads polygon coordinates from augmented_2_micropads/[phone]/coordinates.txt
    and creates YOLOv11 segmentation labels in augmented_1_dataset/[phone]/labels/.

    Format: class_id x1 y1 x2 y2 x3 y3 x4 y4 (normalized [0,1])

    Returns:
        Tuple of (total_labels_created, total_polygons_processed)
    """
    total_labels = 0
    total_polygons = 0

    micropads_dir = PROJECT_ROOT / "augmented_2_micropads"

    for phone in PHONE_DIRS:
        coord_file = micropads_dir / phone / "coordinates.txt"
        if not coord_file.exists():
            print(f"⚠️  Warning: coordinates.txt not found for {phone}")
            continue

        labels_dir = AUGMENTED_DATASET / phone / "labels"
        labels_dir.mkdir(parents=True, exist_ok=True)

        # Read coordinates (format: image concentration x1 y1 x2 y2 x3 y3 x4 y4 rotation)
        with open(coord_file, 'r') as f:
            lines = f.readlines()

        # Skip header line if present (case-insensitive, handle whitespace)
        if lines and lines[0].strip().lower().startswith('image'):
            lines = lines[1:]

        # Group polygons by image
        image_polygons = {}
        for line in lines:
            parts = line.strip().split()
            if len(parts) < 10:
                print(f"⚠️  Warning: malformed coordinate line (expected 10 fields, got {len(parts)}): {line.strip()[:80]}")
                continue

            img_name = parts[0]
            # Remove _con_N suffix to get base image name (handles names with underscores)
            # Format: {base_name}_con_{N} where base_name may contain underscores
            if '_con_' in img_name:
                # Find last occurrence of _con_ pattern
                idx = img_name.rfind('_con_')
                base_name = img_name[:idx]
            else:
                # Fallback: no _con_ suffix (shouldn't happen but safe)
                base_name = img_name

            # Extract polygon vertices (columns 2-9: x1 y1 x2 y2 x3 y3 x4 y4)
            vertices = [float(parts[i]) for i in range(2, 10)]
            polygon = [(vertices[i], vertices[i+1]) for i in range(0, 8, 2)]

            if base_name not in image_polygons:
                image_polygons[base_name] = []
            image_polygons[base_name].append(polygon)

        # Get image dimensions and create labels
        images_dir = AUGMENTED_DATASET / phone / "images"
        for base_name, polygons in image_polygons.items():
            # Find corresponding image file
            img_path = None
            for ext in ['.jpg', '.jpeg', '.png']:
                candidate = images_dir / f"{base_name}{ext}"
                if candidate.exists():
                    img_path = candidate
                    break

            if img_path is None:
                print(f"⚠️  Warning: image not found for {base_name}")
                continue

            # Get image dimensions
            img = cv2.imread(str(img_path))
            if img is None:
                print(f"⚠️  Warning: failed to read {img_path}")
                continue
            height, width = img.shape[:2]

            # Validate coordinates are within image bounds
            valid_polygons = []
            for polygon in polygons:
                if all(0 <= x < width and 0 <= y < height for x, y in polygon):
                    valid_polygons.append(polygon)
                else:
                    print(f"⚠️  Warning: polygon outside image bounds in {base_name} (image: {width}x{height})")

            if not valid_polygons:
                print(f"⚠️  Warning: no valid polygons for {base_name}, skipping")
                continue

            # Write label file with only valid polygons
            label_path = labels_dir / f"{base_name}.txt"
            with open(label_path, 'w') as f:
                for polygon in valid_polygons:
                    # Normalize coordinates to [0, 1]
                    norm_poly = [(x / width, y / height) for x, y in polygon]
                    # Write: 0 x1 y1 x2 y2 x3 y3 x4 y4
                    coords_str = ' '.join([f"{x:.6f} {y:.6f}" for x, y in norm_poly])
                    f.write(f"0 {coords_str}\n")
                    total_polygons += 1

            total_labels += 1

    print(f"✅ Generated {total_labels} label files ({total_polygons} polygons)")
    return total_labels, total_polygons


def create_train_val_txt() -> Tuple[int, int]:
    """Create train.txt and val.txt with image paths."""
    # Collect training images (3 phones)
    train_images = []
    for phone in TRAIN_PHONES:
        train_images.extend(collect_image_paths(phone))

    # Collect validation images (1 phone)
    val_images = collect_image_paths(VAL_PHONE)

    # Write train.txt
    train_txt = AUGMENTED_DATASET / "train.txt"
    with open(train_txt, 'w') as f:
        for img_path in train_images:
            f.write(f"{img_path}\n")

    # Write val.txt
    val_txt = AUGMENTED_DATASET / "val.txt"
    with open(val_txt, 'w') as f:
        for img_path in val_images:
            f.write(f"{img_path}\n")

    print(f"✅ Created {train_txt}")
    print(f"   - Train images: {len(train_images)} (phones: {', '.join(TRAIN_PHONES)})")
    print(f"✅ Created {val_txt}")
    print(f"   - Val images: {len(val_images)} (phone: {VAL_PHONE})")

    return len(train_images), len(val_images)


def create_yolo_config(config_name: str, description: str) -> Path:
    """Create YOLO dataset configuration file."""
    config = {
        'path': AUGMENTED_DATASET.absolute().as_posix(),
        'train': 'train.txt',
        'val': 'val.txt',
        'nc': 1,
        'names': ['concentration_zone']
    }

    config_path = CONFIGS_DIR / f"{config_name}.yaml"
    with open(config_path, 'w') as f:
        f.write(f"# {description}\n")
        f.write(f"# Generated by prepare_yolo_dataset.py\n\n")
        yaml.dump(config, f, default_flow_style=False, sort_keys=False)

    print(f"✅ Created {config_path}")
    return config_path


def print_summary(train_count: int, val_count: int, label_count: int, polygon_count: int) -> None:
    """Print dataset summary."""
    print("\n" + "="*60)
    print("YOLO Dataset Preparation Complete")
    print("="*60)
    print(f"Dataset path: {AUGMENTED_DATASET}")
    print(f"Train phones: {', '.join(TRAIN_PHONES)}")
    print(f"Val phone: {VAL_PHONE}")
    print(f"Train images: {train_count}")
    print(f"Val images: {val_count}")
    print(f"Total images: {train_count + val_count}")
    print(f"YOLO labels: {label_count} files")
    print(f"Total polygons: {polygon_count}")
    print(f"Classes: 1 (concentration_zone)")
    print(f"Config directory: {CONFIGS_DIR}")
    print("="*60)
    print("\nNext steps:")
    print("1. Activate environment: conda activate microPAD-python-env")
    print("2. Train model:")
    print("   python python_scripts/train_yolo.py --stage 1")
    print("   (YOLO scales images to 960x960 at runtime)")
    print("   Or customize resolution:")
    print("   python python_scripts/train_yolo.py --stage 1 --imgsz 960 --batch 24")
    print("="*60)


def verify_labels() -> bool:
    """Verify that label files exist for all images.

    Returns:
        True if all labels exist, False otherwise
    """
    missing_labels = []

    for phone in PHONE_DIRS:
        images = collect_image_paths(phone, use_absolute_paths=True)
        labels_dir = AUGMENTED_DATASET / phone / "labels"

        for img_path in images:
            img_name = Path(img_path).stem
            label_path = labels_dir / f"{img_name}.txt"

            if not label_path.exists():
                missing_labels.append(str(label_path))

    if missing_labels:
        print(f"⚠️  Warning: {len(missing_labels)} label files missing:")
        for label in missing_labels[:5]:
            print(f"   - {label}")
        if len(missing_labels) > 5:
            print(f"   ... and {len(missing_labels) - 5} more")
        return False
    else:
        print(f"✅ All label files verified")
        return True


def main() -> None:
    """Main execution.

    Raises:
        FileNotFoundError: If dataset or phone directories not found
        ValueError: If no images found in directories
    """
    print("="*60)
    print("microPAD YOLO Dataset Preparation")
    print("="*60)

    if not AUGMENTED_DATASET.exists():
        raise FileNotFoundError(f"Dataset not found at {AUGMENTED_DATASET}")

    for phone in PHONE_DIRS:
        phone_path = AUGMENTED_DATASET / phone
        if not phone_path.exists():
            raise FileNotFoundError(f"Phone directory not found: {phone_path}")

    print(f"✅ Dataset found: {AUGMENTED_DATASET}")
    print(f"✅ Phone directories: {', '.join(PHONE_DIRS)}\n")

    print("Restructuring dataset for YOLO...")
    moved_count = restructure_for_yolo()
    if moved_count > 0:
        print(f"✅ Restructured: moved {moved_count} images to images/ subdirectories")
    else:
        print(f"✅ Already restructured: images already in images/ subdirectories")
    print()

    cache_files = list(AUGMENTED_DATASET.glob("*.cache"))
    if cache_files:
        for cache_file in cache_files:
            cache_file.unlink()
        print(f"✅ Deleted {len(cache_files)} cache files")
        print()

    # Generate YOLO labels from MATLAB coordinates
    print("Generating YOLO labels from MATLAB coordinates...")
    label_count, polygon_count = generate_yolo_labels()
    print()

    verify_labels()
    print()

    train_count, val_count = create_train_val_txt()
    print()

    create_yolo_config(
        "micropad_synth",
        "microPAD Synthetic Dataset - Train on 3 phones, validate on 1 phone"
    )

    print_summary(train_count, val_count, label_count, polygon_count)


if __name__ == "__main__":
    main()
