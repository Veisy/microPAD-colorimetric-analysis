# microPAD colorimetric analysis

A MATLAB-based colorimetric analysis pipeline for microfluidic paper-based analytical devices (microPADs). Processes smartphone images of test strips to extract color features and predict biomarker concentrations (urea, creatinine, lactate) using machine learning.

![Pipeline Overview](demo_images/stage1_original_image.jpeg)

## Table of Contents
- [Requirements](#requirements)
- [Dataset Structure](#dataset-structure)
- [Pipeline Stages](#pipeline-stages)
- [Quick Start](#quick-start)
- [Data Augmentation](#data-augmentation)
- [Helper Scripts](#helper-scripts)
- [Directory Layout](#directory-layout)
- [Tips and Troubleshooting](#tips-and-troubleshooting)
- [Output Example](#output-example)
- [Future Work: Android Smartphone Application](#future-work-android-smartphone-application)

---

## Requirements

- **MATLAB R2020a or later** with Image Processing Toolbox
- Run scripts from the project folder or `matlab_scripts/` folder

---

## Dataset Structure

### Phone Models & Lighting Conditions

The dataset is organized by **phone model** (e.g., `iphone_11/`, `samsung_a75/`, `realme_c55/`). Each phone captures **7 images per microPAD**, representing different lighting combinations using 3 laboratory lamps:

| Lighting ID | Lamp 1 | Lamp 2 | Lamp 3 | Description |
|-------------|--------|--------|--------|-------------|
| **light_1** | âœ“ | âœ— | âœ— | Only lamp 1 |
| **light_2** | âœ— | âœ“ | âœ— | Only lamp 2 |
| **light_3** | âœ— | âœ— | âœ“ | Only lamp 3 |
| **light_4** | âœ“ | âœ“ | âœ— | Lamps 1 + 2 |
| **light_5** | âœ“ | âœ— | âœ“ | Lamps 1 + 3 |
| **light_6** | âœ— | âœ“ | âœ“ | Lamps 2 + 3 |
| **light_7** | âœ“ | âœ“ | âœ“ | All lamps |

This lighting variation helps the model work well under different real-world lighting conditions.

### microPAD Structure

Each microPAD paper strip contains **7 test zones** (concentrations), and each test zone has **3 elliptical measurement regions**:

- **Final design:** The 3 regions will contain different chemicals (urea, creatinine, lactate)
- **Training phase:** All 3 regions contain the same chemical at the same concentration, providing 3 replicate measurements per concentration level
- This allows separate datasets to be collected for training machine learning models for each chemical

---

## Pipeline Stages

The pipeline processes images through **4 sequential stages**. Each stage reads from folder `N_*` and writes to `(N+1)_*`:

### **Stage 1 â†’ 2: Cut microPAD Concentration Regions**

**Script:** `cut_micropads.m`

**Input:** Raw smartphone photos in `1_dataset/{phone_model}/`
**Output:** Individual concentration rectangles in `2_micropads/{phone_model}/con_{N}/`

![Stage 1 to 2](demo_images/stage2_micropad.jpeg)

Processes raw smartphone images in a single step: applies optional rotation, uses AI-powered polygon detection (YOLOv11 segmentation) to locate test zones, and crops individual concentration regions. Combines the functionality of the previous two-step process into one streamlined workflow.

**Key Features:**
- AI-based auto-detection of test zones (YOLOv11n segmentation, 99.5% mask mAP@50)
- Graceful fallback to manual polygon selection if auto-detection fails
- Interactive rotation control with cumulative rotation memory
- Saves 10-column coordinate format: `image concentration x1 y1 x2 y2 x3 y3 x4 y4 rotation`

---

### **Stage 2 â†’ 3: Extract Elliptical Patches**

**Script:** `cut_elliptical_regions.m`

**Input:** Concentration rectangles from `2_micropads/`
**Output:** Elliptical patches in `3_elliptical_regions/{phone_model}/con_{N}/`

![Stage 2 to 3](demo_images/stage3_elliptical_region_1.jpeg)

Extracts three elliptical measurement regions from each test zone. In the final microPAD design, these three regions will contain different chemicals (urea, creatinine, lactate). For training purposes, each experiment fills all three regions with the same concentration of a single chemical, providing three replicate measurements per concentration level.

---

### **Stage 3 â†’ 4: Feature Extraction**

**Script:** `extract_features.m`

**Input:**
- Concentration rectangles from `2_micropads/` (used as paper/white reference)
- Elliptical patches from `3_elliptical_regions/`

**Output:** Excel feature tables in `4_extract_features/`

![White Reference Strategy](demo_images/white_referenced_pixels_on_rectangle.png)

Extracts 80+ colorimetric features from elliptical test zones while compensating for varying lighting conditions using the white paper as a reference. This enables robust biomarker concentration prediction under different smartphone cameras and lighting environments.

---

#### **White Reference Strategy**

The pipeline automatically samples white paper pixels **outside the three elliptical test regions** within each concentration rectangle (shown in green above). These reference pixels provide:

1. **Illuminant estimation** - Determines color temperature of the lighting (2500-10000K)
2. **Chromatic adaptation** - Normalizes color channels to compensate for lighting color cast
3. **Reflectance calculation** - Converts RGB values to relative reflectance ratios
4. **Delta-E baseline** - Measures color difference from paper white point in perceptually-uniform Lab space

This approach makes features **lighting-invariant** across different phone models and laboratory conditions.

---

#### **Available Presets**

```matlab
extract_features('preset','robust','chemical','lactate')  % Recommended
extract_features('preset','minimal')  % Fast, essential features only
extract_features('preset','full')     % All 150+ features
extract_features('preset','custom')   % Interactive feature group selection dialog
```

| Preset | Feature Count | Description |
|--------|---------------|-------------|
| **minimal** | ~30 | Essential color ratios and basic statistics |
| **robust** | ~80 | Comprehensive set balancing accuracy and speed (recommended) |
| **full** | ~150 | All available features including advanced texture analysis |
| **custom** | Variable | User-defined via interactive dialog or struct |

---

#### **Extracted Features (Robust Preset)**

**Color Normalization (Paper-Referenced)**
- RGB ratios relative to paper white point (R/R_paper, G/G_paper, B/B_paper)
- Lab color corrected for paper baseline (L*, a*, b* shifts)
- Delta-E color difference from paper (perceptually uniform)
- Chromatic adaptation factors (von Kries-style)

**Lighting-Invariant Color Ratios**
- Red/Green, Red/Blue, Green/Blue channel ratios
- Hue-based features immune to brightness changes
- Normalized chroma and saturation metrics

**Color Space Statistics**
- RGB: Mean, median, standard deviation per channel
- HSV: Hue, saturation, value distributions
- Lab: Lightness (L*), red-green (a*), blue-yellow (b*) statistics

**Texture and Spatial Features**
- Edge sharpness (gradient magnitude)
- Color uniformity (coefficient of variation)
- Spatial frequency patterns (FFT-based)
- Local color gradients

**Advanced Colorimetry**
- Estimated illuminant color temperature (Kelvin)
- Color purity and dominance wavelength
- Entropy and histogram statistics

---

#### **Output Format**

Excel files with one row per elliptical measurement (replicate):

| PhoneType | ImageName | RG_ratio | delta_E_from_paper | R_paper_ratio | Label |
|-----------|-----------|----------|-------------------|---------------|-------|
| iphone_11 | IMG_0957_aug_000_con_0.png | 0.461 | 32.04 | 0.723 | 0 |
| iphone_11 | IMG_0957_aug_000_con_0.png | 0.460 | 31.51 | 0.719 | 0 |
| iphone_11 | IMG_0957_aug_000_con_0.png | 0.462 | 32.23 | 0.728 | 0 |

- Each concentration zone contributes **3 rows** (3 elliptical replicates)
- `Label` column = known concentration (0-6) for supervised learning
- Automatically exports train/test splits (70/30 default, stratified by image)

---

#### **Parameters**

```matlab
% Chemical name (used in output filename)
extract_features('chemical', 'urea')

% White reference override (if auto-detection fails)
extract_features('paperTempK', 6000)

% Train/test split control
extract_features('trainTestSplit', true, 'testSize', 0.25, 'randomSeed', 42)

% Custom feature selection without dialog
customFeatures = struct('ColorRatios', true, 'PaperNormalization', true);
extract_features('preset', 'custom', 'features', customFeatures, 'useDialog', false)
```

---

#### **Machine Learning Integration**

The extracted features are designed for training AI models that will:
1. **Predict biomarker concentrations** from smartphone images
2. **Run on Android smartphones** via embedded TensorFlow Lite models
3. **Auto-detect test zones** using YOLOv11 segmentation (already integrated in MATLAB pipeline)

**Typical ML workflow:**
```matlab
% 1. Extract features in MATLAB
extract_features('preset','robust','chemical','lactate')

% 2. Load train/test splits in Python
train_df = pd.read_excel('4_extract_features/robust_lactate_train_features.xlsx')
test_df = pd.read_excel('4_extract_features/robust_lactate_test_features.xlsx')

% 3. Train regression model
X_train = train_df.drop(['PhoneType','ImageName','Label'], axis=1)
y_train = train_df['Label']
model = RandomForestRegressor()
model.fit(X_train, y_train)

% 4. Export for Android deployment
# Convert to TensorFlow Lite for smartphone inference
```

---

## Quick Start

Run these commands **in order** from the project folder:

### Full Pipeline (from raw images)

```bash
# Stage 1â†’2: Cut microPAD concentration regions (with AI detection)
matlab -batch "addpath('matlab_scripts'); cut_micropads;"

# Stage 2â†’3: Extract elliptical regions
matlab -batch "addpath('matlab_scripts'); cut_elliptical_regions;"

# Stage 3â†’4: Extract features (change 'lactate' to your chemical name)
matlab -batch "addpath('matlab_scripts'); extract_features('preset','robust','chemical','lactate');"
```

### Typical Workflow (starting from Stage 2)

If you already have concentration rectangles in `2_micropads/`:

```bash
matlab -batch "addpath('matlab_scripts'); cut_elliptical_regions;"
matlab -batch "addpath('matlab_scripts'); extract_features('preset','robust','chemical','lactate');"
```

---

## Data Augmentation

**Script:** `augment_dataset.m` (optional, recommended for AI training)

Generates synthetic training data by transforming real microPAD images and concentration polygons and composing them onto procedural backgrounds. Essential for training robust polygon detection models for the Android smartphone application.

![Augmented Dataset](demo_images/augmented_dataset_1.png)
*Synthetic scene with transformed microPAD under simulated lighting*

![Augmented microPAD](demo_images/augmented_micropad_1.png)
*Augmented concentration region with perspective distortion*

![Augmented Ellipse](demo_images/augmented_elliptical_region1.png)
*Augmented elliptical patch preserving colorimetric properties*

---

### **Why Augmentation is Critical**

The final Android application will use AI-based **auto-detection** to locate test zones in smartphone photos. Augmentation **multiplies the training dataset** by 5-10x without requiring additional physical experiments, generating diverse viewpoints, lighting conditions, and backgrounds.

**MATLAB augmentation** creates synthetic image transformations following the standard 1â†’2â†’3 pipeline structure. **Python scripts** then prepare YOLO training labels from the MATLAB-generated coordinates.

---

### **Transformation Pipeline**

**Geometric Transformations (per region)**
1. **3D perspective projection** - Simulates camera viewing angles (+/-60 deg pitch/yaw)
2. **Rotation** - Random orientation (0-360 deg)
3. **Spatial placement** - Random non-overlapping positions via grid acceleration
4. **Optional per-region rotation** - Independent orientation for each concentration zone

**Photometric Augmentation**
- **Brightness/contrast** - Global illumination variation (Â±5-10%)
- **White balance jitter** - Per-channel gains simulating different lighting (0.92-1.08x)
- **Saturation adjustment** - Color intensity variation (0.94-1.06x)
- **Gamma correction** - Exposure simulation (0.92-1.08)

**Background Generation (Procedural)**
- **Uniform surfaces** - Clean laboratory benches (220 +/- 15 RGB)
- **Speckled textures** - Granite, composite materials
- **Laminate** - High-contrast white/black surfaces (245 or 30 RGB)
- **Skin tones** - Human hand/arm backgrounds (HSV-based)
- **Texture pooling** - 16 cached variants per surface type with random shifts, flips, and scale jitter to avoid regeneration artifacts

**Distractor Artifacts (5-40 per image)**
- **Shapes**: Ellipses, rectangles, quadrilaterals, triangles, lines
- **Sizes**: 1-75% of image diagonal (allows partial occlusions)
- **Placement**: Unconstrained (can extend beyond frame)
- **Sharpness**: Sharp by default, matching concentration rectangle behavior
- **Rendering**: Nearest-neighbor interpolation to preserve crisp edges
- **Purpose**: Train polygon detector to ignore false positives while maintaining realistic appearance

**Distractor Polygons (Synthetic Look-Alikes)**
- **Count**: Random 1-10 per image (independent of real polygon count)
- **Size Variation**: Each distractor randomly scaled 50%-150% of source polygon size
- **Appearance**: Synthesized from real polygons with jittered colors and textures
- **Placement**: Non-overlapping collision detection, respects spacing constraints
- **Purpose**: Train AI to distinguish real test zones from similar-looking objects by position/context rather than appearance alone

**Blur and Occlusions (Optional)**
- **Scene-wide blur** - Applied to entire image (polygons + artifacts) when enabled
- **Motion blur** - Camera shake simulation (15% probability)
- **Gaussian blur** - Focus variation (25% probability, sigma 0.25-0.65px)
- **Thin occlusions** - Hair/strap-like artifacts across test zones (disabled by default)

---

### **Usage Examples**

```matlab
% Basic usage: 5 augmented versions per paper (6 total with original)
augment_dataset('numAugmentations', 5, 'rngSeed', 42)

% High-augmentation mode for deep learning (10x data)
augment_dataset('numAugmentations', 10, 'photometricAugmentation', true)

% Enable all augmentation features
augment_dataset('numAugmentations', 5, ...
                'photometricAugmentation', true, ...
                'blurProbability', 0.30, ...
                'motionBlurProbability', 0.20, ...
                'occlusionProbability', 0.15, ...
                'independentRotation', true)

% Fast mode: disable expensive features
augment_dataset('numAugmentations', 3, ...
                'photometricAugmentation', false, ...
                'independentRotation', false)

% Reproducible augmentation for ablation studies
augment_dataset('numAugmentations', 5, 'rngSeed', 12345)

% Emit JSON labels for CornerNet-style training
augment_dataset('numAugmentations', 5, 'exportCornerLabels', true)
```

---

### **Performance**

**Speed**: ~1.0 second per augmented image (3x faster than v1)
- Grid-based spatial acceleration (O(1) collision detection vs O(n^2))
- Simplified polygon warping (nearest-neighbor vs bilinear)
- Background texture pooling (reuses 4 procedural types with cached surfaces instead of regenerating each frame)

**Memory**: Low overhead
- Processes one paper at a time
- Temporary buffers released after each scene

**Scalability**: Handles large datasets
- Automatic background expansion if polygons don't fit
- Graceful degradation on positioning failures

---

### **Input/Output Structure**

**Inputs:**
- `1_dataset/{phone}/` - Original smartphone images
- `2_micropads/{phone}/coordinates.txt` - Polygon vertices (required)
- `3_elliptical_regions/{phone}/coordinates.txt` - Ellipse parameters (optional)

**Outputs:**
- `augmented_1_dataset/{phone}/` - Full synthetic scenes
- `augmented_2_micropads/{phone}/con_{N}/` - Transformed concentration regions + coordinates.txt
- `augmented_3_elliptical_regions/{phone}/con_{N}/` - Transformed elliptical patches + coordinates.txt (if input ellipses exist)

**YOLO Training Labels:** Generated by Python scripts from MATLAB coordinates (see Python pipeline documentation)

**Naming convention:**
- Original: `paper_name_aug_000.png` (identity transformations)
- Augmented: `paper_name_aug_001.png`, `paper_name_aug_002.png`, etc.

---

### **Integration with ML Pipeline**

**For Polygon Detection (YOLO, Faster R-CNN)**
```python
# 1. Generate augmented data in MATLAB
augment_dataset('numAugmentations', 5)

# 2. Prepare YOLO dataset with Python (reads MATLAB coordinates, creates labels)
python python_scripts/prepare_yolo_dataset.py

# 3. Train model
python python_scripts/train_yolo.py
```

**For Concentration Prediction (Regression Models)**
```matlab
% Extract features from augmented data
extract_features('preset','robust','chemical','lactate')
% Output: 4_extract_features/ with (N+1) Ã— original sample count
```

**For Android Deployment**
1. Train polygon detector on `augmented_1_dataset/`
2. Export to TensorFlow Lite (.tflite)
3. Train concentration predictor on features from augmented ellipses
4. Embed both models in Android app

---

### **Important Notes**

**Ellipse coordinate propagation:**
- If `3_elliptical_regions/coordinates.txt` is missing, augmentation still runs but only produces stages 1-2
- To generate augmented ellipses without pre-existing coordinates, run `cut_elliptical_regions.m` on `augmented_2_micropads/` after augmentation

**Coordinate preservation:**
- All transformations (perspective, rotation, translation) are recorded in output coordinates.txt files
- Ellipse transformations use conic section mathematics to preserve accuracy
- Coordinates are validated (degenerate ellipses/polygons are skipped with warnings)

**Quality control:**
- Original version (aug_000) uses identity transformations for debugging
- Photometric augmentation is color-safe (preserves relative hue relationships)
- At most one blur type is applied per image (prevents over-softening)

---

## Helper Scripts

Three utility scripts in `matlab_scripts/helper_scripts/` for recreating images and checking quality:

### **extract_images_from_coordinates.m**

Recreates all processed images from `coordinates.txt` files. Instead of saving thousands of image files, you only need to keep small text files with coordinates.

**Why this matters:**
- You don't need to save processed images (stages 2-4) - just keep the `coordinates.txt` files
- Anyone can recreate the exact same images from the coordinates
- Saves storage space (gigabytes â†’ kilobytes)

**Usage:**
```matlab
addpath('matlab_scripts/helper_scripts');
extract_images_from_coordinates();
```

Run this script to recreate any missing processed images from your saved coordinates.

---

### **preview_overlays.m**

Opens a viewer that shows how well your coordinates match the actual images. Displays rectangles, polygons, and ellipses overlaid on the original photos.

**Use this to:**
- Check if your annotations are accurate
- Find mistakes before extracting features
- Verify your work after editing `coordinates.txt` files

**Usage:**
```matlab
addpath('matlab_scripts/helper_scripts');
preview_overlays();  % Press 'n' to navigate, 'q' to quit
```

---

### **preview_augmented_overlays.m**

Same as `preview_overlays.m`, but for checking the augmented (synthetic) dataset quality.

**Usage:**
```matlab
addpath('matlab_scripts/helper_scripts');
preview_augmented_overlays();
```

---

## Directory Layout

```
microPAD-colorimetric-analysis/
â”œâ”€â”€ matlab_scripts/          # Main processing scripts
â”‚   â”œâ”€â”€ cut_micropads.m      # Stage 1â†’2 (AI detection + cropping)
â”‚   â”œâ”€â”€ cut_elliptical_regions.m  # Stage 2â†’3
â”‚   â”œâ”€â”€ extract_features.m   # Stage 3â†’4
â”‚   â”œâ”€â”€ augment_dataset.m    # Data augmentation (optional)
â”‚   â””â”€â”€ helper_scripts/      # Utility functions
â”œâ”€â”€ 1_dataset/               # Raw smartphone photos
â”‚   â”œâ”€â”€ iphone_11/
â”‚   â”œâ”€â”€ iphone_15/
â”‚   â”œâ”€â”€ realme_c55/
â”‚   â””â”€â”€ samsung_a75/
â”œâ”€â”€ 2_micropads/             # Concentration regions + coordinates.txt
â”œâ”€â”€ 3_elliptical_regions/    # Elliptical patches + coordinates.txt
â”œâ”€â”€ 4_extract_features/      # Feature tables (.xlsx)
â”œâ”€â”€ augmented_1_dataset/     # (Optional) Synthetic scenes
â”œâ”€â”€ augmented_2_micropads/
â”œâ”€â”€ augmented_3_elliptical_regions/
â””â”€â”€ demo_images/             # Visual examples for documentation
```

**Note:** The processed images are not saved to version control (only the `coordinates.txt` files are saved).

---

## Tips and Troubleshooting

### Coordinate Files

Each stage saves a `coordinates.txt` file with position and shape information:
- **Stage 2 (2_micropads):** Corner points (4 vertices) + rotation for each test zone
- **Stage 3 (3_elliptical_regions):** Ellipse center, semi-major/minor axes, and rotation angle

**If corrupted:** Delete the file and re-run the stage to create a new one.

### Memory Issues

If MATLAB runs out of memory, process fewer images at once:

```matlab
extract_features('preset', 'robust', 'batchSize', 10)
```

### Running from the Wrong Folder

If you see warnings about missing folders, make sure you're running scripts from:
- The main project folder, OR
- The `matlab_scripts/` folder

### Testing Before Full Processing

Before processing all images, test with 2-3 sample images to make sure everything works correctly.

---

## Output Example

Sample rows from `4_extract_features/robust_lactate_features.xlsx` (showing subset of 80+ feature columns):

| PhoneType  | ImageName                   | RG_ratio | RB_ratio | GB_ratio | L       | a       | b      | delta_E_from_paper | R_paper_ratio | Label |
|------------|-----------------------------|----------|----------|----------|---------|---------|--------|--------------------|---------------|-------|
| iphone_11  | IMG_0957_aug_000_con_0.png | 0.461449 | 0.360812 | 0.781910 | 53.9623 | 10.3421 | 18.952 | 32.0361            | 0.7234        | 0     |
| iphone_11  | IMG_0957_aug_000_con_0.png | 0.460265 | 0.365116 | 0.793272 | 54.0647 | 10.1204 | 19.124 | 31.5070            | 0.7189        | 0     |
| iphone_15  | IMG_1234_aug_000_con_3.png | 0.483148 | 0.388192 | 0.803463 | 55.1563 | 11.8934 | 20.456 | 30.2742            | 0.7512        | 3     |
| realme_c55 | IMG_5678_aug_000_con_5.png | 0.492301 | 0.395421 | 0.810234 | 56.2341 | 12.4567 | 21.345 | 29.1234            | 0.7634        | 5     |
| samsung_a75| IMG_9012_aug_000_con_6.png | 0.501234 | 0.402345 | 0.821345 | 57.3456 | 13.2345 | 22.456 | 28.3456            | 0.7789        | 6     |

**Notes:**
- Each row represents one elliptical region measurement (replicate)
- Multiple rows with the same concentration indicate replicate measurements from the 3 elliptical regions within that test zone
- `Label` column shows the known concentration (0-6) for training the model
- During training, all 3 replicates per test zone contain the same chemical at the same concentration
- Full table has 80+ columns (only some shown above)
- Can split data into separate training and testing files

---

## Future Work: Android Smartphone Application

This MATLAB pipeline serves as the **data preparation and training infrastructure** for an Android smartphone application that will:

1. **Capture microPAD photos** using the smartphone camera
2. **Auto-detect test zones** using polygon detection AI (YOLOv11 segmentation - already integrated in MATLAB)
3. **Predict biomarker concentrations** (urea, creatinine, lactate) using regression models (trained on features from `4_extract_features/`)
4. **Display results** to the user in real-time

### **AI Model Training Workflow**

```
MATLAB Pipeline (this repository)
    â†“
augmented_1_dataset/ â†’ Train polygon detector (YOLOv11n segmentation)
    â†“
4_extract_features/ â†’ Train concentration predictor (Random Forest/XGBoost)
    â†“
Export models (PyTorch for MATLAB, TFLite for Android)
    â†“
Android Application (separate repository, coming soon)
```

### **Key Features of Android App**

- **Real-time detection** - Auto-locate test zones in live camera feed (using YOLOv11n model)
- **Lighting compensation** - White reference strategy (same as MATLAB pipeline)
- **Multi-biomarker support** - Separate models for urea, creatinine, lactate
- **Offline inference** - Embedded TensorFlow Lite models (no internet required)
- **Result history** - Save and track measurements over time

### **Current Status**

âœ… **Completed**: MATLAB data preparation pipeline (4-stage pipeline)
âœ… **Completed**: AI polygon detection training (YOLOv11n, 99.5% mask mAP@50)
âœ… **Completed**: MATLAB integration with graceful fallback to manual selection
ðŸ“‹ **Planned**: Android application development with TFLite deployment

Stay tuned for the Android app repository link!
